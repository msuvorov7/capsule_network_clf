{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzOBjZvPaD3A",
        "outputId": "e5019a5b-75d7-483a-966b-0d84c5fa315d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdata\n",
            "  Downloading torchdata-0.3.0-py3-none-any.whl (47 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▉                         | 10 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 20 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 30 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 40 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 47 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 29.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Installing collected packages: urllib3, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed torchdata-0.3.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "\n",
        "def get_imdb():\n",
        "    train_iter, test_iter = IMDB()\n",
        "    return train_iter, test_iter\n"
      ],
      "metadata": {
        "id": "_HRXLFX0aI_x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "def collate_pad(batch) -> dict:\n",
        "    max_len = max(len(row[\"feature\"]) for row in batch)\n",
        "\n",
        "    feature = torch.empty((len(batch), max_len), dtype=torch.long)\n",
        "    labels = torch.empty(len(batch), dtype=torch.long)\n",
        "\n",
        "    for idx, row in enumerate(batch):\n",
        "        to_pad = max_len - len(row[\"feature\"])\n",
        "        feature[idx] = torch.cat((row[\"feature\"], torch.zeros(to_pad)))\n",
        "        labels[idx] = row['label']\n",
        "    return {\n",
        "        'feature': feature,\n",
        "        'label': labels,\n",
        "    }\n",
        "\n",
        "\n",
        "def collate_caps(batch) -> dict:\n",
        "    max_len = 1024\n",
        "\n",
        "    feature = torch.empty((len(batch), max_len), dtype=torch.long)\n",
        "    labels = torch.empty(len(batch), dtype=torch.long)\n",
        "\n",
        "    for idx, row in enumerate(batch):\n",
        "        if len(row[\"feature\"]) <= max_len:\n",
        "            to_pad = max_len - len(row[\"feature\"])\n",
        "            feature[idx] = torch.cat((row[\"feature\"], torch.zeros(to_pad)))\n",
        "        else:\n",
        "            feature[idx] = row[\"feature\"][:max_len]\n",
        "        labels[idx] = row['label']\n",
        "    return {\n",
        "        'feature': feature,\n",
        "        'label': labels,\n",
        "    }\n",
        "\n",
        "\n",
        "def build_dataloader(dataset: Dataset, batch_size: int, collate_fn) -> DataLoader:\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
        "    return loader\n"
      ],
      "metadata": {
        "id": "Gr5CpPGzaQnh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, text: list, label: list):\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return {\n",
        "            'feature': torch.tensor(self.text[item]),\n",
        "            'label': torch.tensor(self.label[item])\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n"
      ],
      "metadata": {
        "id": "MHWiK_fTaXGY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "\n",
        "def build_vocabulary(train_iter):\n",
        "    counter = Counter()\n",
        "    for (label, line) in train_iter:\n",
        "        counter.update(tokenizer(line))\n",
        "\n",
        "    counter = counter.most_common(40_000)\n",
        "    counter = list(filter(lambda word: word[1] > 20, counter))\n",
        "\n",
        "    vocabulary = ['<PAD>', '<UNK>']\n",
        "    vocabulary += [key for key, _ in counter]\n",
        "\n",
        "    ind_to_word = dict(enumerate(vocabulary))\n",
        "    word_to_ind = {value: key for key, value in ind_to_word.items()}\n",
        "\n",
        "    return ind_to_word, word_to_ind\n",
        "\n",
        "\n",
        "def build_feature(iterator, word_to_ind: dict):\n",
        "    X_set, y_set = [], []\n",
        "    for (label, line) in iterator:\n",
        "        x = list(map(lambda word: word_to_ind.get(word, word_to_ind['<UNK>']), tokenizer(line)))\n",
        "        y = 1 if label == 'pos' else 0\n",
        "        X_set.append(x)\n",
        "        y_set.append(y)\n",
        "    return X_set, y_set\n"
      ],
      "metadata": {
        "id": "gHXHWpOpaYvk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GRUBaseline(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(input_size=embedding_dim,\n",
        "                          hidden_size=hidden_dim,\n",
        "                          num_layers=n_layers,\n",
        "                          batch_first=True,\n",
        "                          )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        packed_output, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = hidden[-1, :, :]\n",
        "\n",
        "        return self.fc(self.dropout(F.relu(hidden)))\n"
      ],
      "metadata": {
        "id": "V6d6oibCaaXy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CNNBaseline(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size: int,\n",
        "            embedding_dim: int,\n",
        "            out_channels: int,\n",
        "            kernel_sizes: list,\n",
        "            output_dim: int,\n",
        "            dropout=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv_0 = nn.Conv1d(in_channels=embedding_dim,\n",
        "                                out_channels=out_channels,\n",
        "                                kernel_size=kernel_sizes[0])  # YOUR CODE GOES HERE\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(in_channels=embedding_dim,\n",
        "                                out_channels=out_channels,\n",
        "                                kernel_size=kernel_sizes[1])  # YOUR CODE GOES HERE\n",
        "\n",
        "        self.conv_2 = nn.Conv1d(in_channels=embedding_dim,\n",
        "                                out_channels=out_channels,\n",
        "                                kernel_size=kernel_sizes[2])  # YOUR CODE GOES HERE\n",
        "\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * out_channels, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        embedded = embedded.permute(0, 2, 1)  # may be reshape here\n",
        "\n",
        "        conved_0 = F.relu(self.conv_0(embedded))\n",
        "        conved_1 = F.relu(self.conv_1(embedded))\n",
        "        conved_2 = F.relu(self.conv_2(embedded))\n",
        "\n",
        "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
        "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
        "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
        "\n",
        "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim=1))\n",
        "\n",
        "        return self.fc(cat)\n"
      ],
      "metadata": {
        "id": "qEQTEYzvrADN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def squash(input_tensor):\n",
        "    squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
        "    output_tensor = squared_norm * input_tensor / ((1.0 + squared_norm) * torch.sqrt(squared_norm))\n",
        "    return output_tensor\n",
        "\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels=256, kernel_size=6):\n",
        "        super(ConvLayer, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv1d(in_channels=in_channels,\n",
        "                              out_channels=out_channels,\n",
        "                              kernel_size=kernel_size,\n",
        "                              stride=1,\n",
        "                              padding=1,\n",
        "                              )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.relu(self.conv(x))\n",
        "\n",
        "\n",
        "class PrimaryCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9):\n",
        "        super(PrimaryCaps, self).__init__()\n",
        "\n",
        "        self.capsules = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=in_channels,\n",
        "                      out_channels=out_channels,\n",
        "                      kernel_size=kernel_size,\n",
        "                      stride=2,\n",
        "                      padding=0,\n",
        "                      ) for _ in range(num_capsules)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = [capsule(x) for capsule in self.capsules]\n",
        "        u = torch.stack(u, dim=1)\n",
        "        u = u.view(x.size(0), 32 * 4 * 3, -1)\n",
        "        return squash(u)\n",
        "\n",
        "\n",
        "class DigitCaps(nn.Module):\n",
        "    def __init__(self, num_capsules=10, num_routes=32 * 4 * 3, in_channels=338, out_channels=16):\n",
        "        super(DigitCaps, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_routes = num_routes\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "    def forward(self, x, use_cuda=True):\n",
        "        batch_size = x.size(0)\n",
        "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
        "\n",
        "        W = torch.cat([self.W] * batch_size, dim=0)\n",
        "        u_hat = torch.matmul(W, x)\n",
        "\n",
        "        b_ij = torch.autograd.Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "        if use_cuda:\n",
        "            b_ij = b_ij.cuda()\n",
        "\n",
        "        num_iterations = 3\n",
        "        for iteration in range(num_iterations):\n",
        "            c_ij = F.softmax(b_ij)\n",
        "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
        "\n",
        "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
        "            v_j = squash(s_j)\n",
        "\n",
        "            if iteration < num_iterations - 1:\n",
        "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
        "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
        "\n",
        "        return v_j.squeeze(1)\n",
        "\n",
        "\n",
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim: int, output_dim: int):\n",
        "        super(CapsNet, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv_layer = ConvLayer(embedding_dim)\n",
        "        self.primary_capsules = PrimaryCaps()\n",
        "        self.digit_capsules = DigitCaps()\n",
        "        self.linear = nn.Linear(10 * 16 * 1, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(x)))\n",
        "        return self.linear(output.view(output.size(0), -1))\n"
      ],
      "metadata": {
        "id": "MFHgT0gJlwGi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def test(model, test_data_loader):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    pbar = tqdm(enumerate(test_data_loader), total=len(test_data_loader), leave=False)\n",
        "    for it, batch in pbar:\n",
        "        text = batch['feature'].to(device)\n",
        "        labels = batch['label'].view(-1, 1).to(device)\n",
        "\n",
        "        prediction = model(text)\n",
        "        preds = torch.max(F.softmax(prediction, dim=1), dim=1)[1]\n",
        "\n",
        "        y_true += labels.cpu().detach().numpy().ravel().tolist()\n",
        "        y_pred += preds.cpu().detach().numpy().ravel().tolist()\n",
        "\n",
        "    print('f1 score:', f1_score(y_true, y_pred))\n",
        "    print('accuracy score:', accuracy_score(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "d5-pEkQ2acLv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_loss(train_loss: list, val_loss: list, model_name: str):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(train_loss, marker='s', label='Train Loss')\n",
        "    plt.plot(val_loss, marker='s', label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.savefig(f'{model_name}_mse_loss.jpg')\n",
        "\n",
        "\n",
        "def plot_acc(train_acc: list, val_acc: list, model_name: str):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(train_acc, marker='s', label='Train ACC')\n",
        "    plt.plot(val_acc, marker='s', label='Validation ACC')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('ACC')\n",
        "    plt.savefig(f'{model_name}_acc.jpg')\n"
      ],
      "metadata": {
        "id": "4O07aJ3Yak6f"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def train(epoch: int,\n",
        "          model: nn.Module,\n",
        "          training_data_loader: DataLoader,\n",
        "          validating_data_loader: DataLoader,\n",
        "          criterion: nn.Module,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          device: str):\n",
        "    train_loss = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for batch in tqdm(training_data_loader):\n",
        "        text, label = batch['feature'], batch['label']\n",
        "        text = text.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        y_predict = model(text)\n",
        "\n",
        "        loss = criterion(y_predict, label)\n",
        "        # print(torch.max(F.softmax(y_predict, dim=1), dim=1)[1])\n",
        "        # print(label)\n",
        "        # print(torch.argmax(F.softmax(y_predict, dim=1), dim=1))\n",
        "        # print(torch.max(F.softmax(y_predict, dim=1), dim=1)[1])\n",
        "        # return\n",
        "        optimizer.zero_grad()\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss /= len(training_data_loader)\n",
        "\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    for batch in tqdm(validating_data_loader):\n",
        "        text = batch['feature'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        prediction = model(text)\n",
        "        preds = torch.max(F.softmax(prediction, dim=1), dim=1)[1]\n",
        "        y_true += labels.cpu().detach().numpy().ravel().tolist()\n",
        "        y_pred += preds.cpu().detach().numpy().ravel().tolist()\n",
        "\n",
        "        loss = criterion(prediction, labels)\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(validating_data_loader)\n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return train_loss, val_loss, val_acc\n",
        "\n",
        "\n",
        "def fit(model: nn.Module, training_data_loader, validating_data_loader, epochs: int, name: str):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    train_accuracy = []\n",
        "    val_accuracy = []\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        train_loss, val_loss, val_acc = train(epoch, model, training_data_loader,\n",
        "                                              validating_data_loader, criterion, optimizer, device)\n",
        "        # val_loss, val_acc = test(model, testing_data_loader, criterion, device)\n",
        "        # checkpoint(epoch, model, 'models')\n",
        "        print('Epoch: {}, Training Loss: {}, Validation Loss: {}, Validation ACC: {}'.format(epoch,\n",
        "                                                                                             train_loss,\n",
        "                                                                                             val_loss,\n",
        "                                                                                             val_acc)\n",
        "              )\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        val_accuracy.append(val_acc)\n",
        "\n",
        "    torch.save(model, f'{name}.model')\n",
        "\n",
        "    plot_acc(train_accuracy, val_accuracy, name)\n",
        "    plot_loss(train_losses, val_losses, name)\n"
      ],
      "metadata": {
        "id": "_j1FG75mad4v"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_iter, test_iter = get_imdb()\n",
        "    _, word_to_ind = build_vocabulary(train_iter)\n",
        "    print('vocab done')\n",
        "    X_train, y_train = build_feature(train_iter, word_to_ind)\n",
        "    X_test, y_test = build_feature(test_iter, word_to_ind)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, random_state=42, test_size=0.5)\n",
        "    print('features done')\n",
        "    train_dataset = IMDBDataset(X_train, y_train)\n",
        "    valid_dataset = IMDBDataset(X_val, y_val)\n",
        "    test_dataset = IMDBDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = build_dataloader(train_dataset, 128, collate_pad)\n",
        "    valid_loader = build_dataloader(valid_dataset, 64, collate_pad)\n",
        "    test_loader = build_dataloader(test_dataset, 64, collate_pad)\n",
        "\n",
        "    # gru_model = GRUBaseline(vocab_size=len(word_to_ind), embedding_dim=100, hidden_dim=256, output_dim=2, n_layers=1)\n",
        "    # cnn_model = CNNBaseline(vocab_size=len(word_to_ind), embedding_dim=100, out_channels=256, output_dim=2, kernel_sizes=[3, 4, 5])\n",
        "    capsule_model = CapsNet(vocab_size=len(word_to_ind), embedding_dim=100, output_dim=2)\n",
        "\n",
        "    # fit(gru_model, train_loader, valid_loader, 10, 'gru_model')\n",
        "    # fit(cnn_model, train_loader, valid_loader, 10, 'cnn_model')\n",
        "\n",
        "    train_cap_loader = build_dataloader(train_dataset, 32, collate_caps)\n",
        "    valid_cap_loader = build_dataloader(valid_dataset, 32, collate_caps)\n",
        "    test_cap_loader = build_dataloader(test_dataset, 32, collate_caps)\n",
        "    \n",
        "    fit(capsule_model, train_cap_loader, valid_cap_loader, 10, 'capsule_model')\n",
        "    \n",
        "    # test(gru_model, test_loader)\n",
        "    # test(cnn_model, test_loader)\n",
        "    test(capsule_model, test_cap_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwcXHB1Rafud",
        "outputId": "0a9f27be-d7ff-48d6-e9e8-d54bdbddd9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab done\n",
            "features done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/782 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            " 46%|████▋     | 363/782 [05:56<06:49,  1.02it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KgWEYAv0ay2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "capsule_net_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}